import sys
import streamlit as st
import os
import logging

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

# è®°å½•ç¨‹åºå¯åŠ¨
logger.info("ç¨‹åºå¼€å§‹è¿è¡Œ")

# åªåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶æ›¿æ¢ sqlite3
if 'sqlite_setup_done' not in st.session_state:
    try:
        logger.info("å°è¯•è®¾ç½® SQLite")
        __import__('pysqlite3')
        sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
        st.session_state.sqlite_setup_done = True
        logger.info("SQLite è®¾ç½®æˆåŠŸ")
    except Exception as e:
        logger.error(f"SQLite è®¾ç½®é”™è¯¯: {str(e)}")
        st.session_state.sqlite_setup_done = True

# åœ¨æ‰€æœ‰å…¶ä»–å¯¼å…¥ä¹‹å‰ï¼Œå…ˆåˆå§‹åŒ–ç¯å¢ƒå˜é‡

# ç«‹å³è®¾ç½®æ‰€æœ‰éœ€è¦çš„API keys
try:
    logger.info("å¼€å§‹è®¾ç½® API keys")
    os.environ['OPENAI_API_KEY'] = st.secrets['OPENAI_API_KEY']
    os.environ['OPENAI_API_BASE'] = "https://openrouter.ai/api/v1"
    os.environ['OPENAI_MODEL_NAME'] = st.secrets['OPENAI_MODEL_NAME']
    
    # å¦‚æœæœ‰å…¶ä»–keyï¼Œä¹Ÿåœ¨è¿™é‡Œè®¾ç½®
    if 'GROQ_API_KEY' in st.secrets:
        os.environ['GROQ_API_KEY'] = st.secrets['GROQ_API_KEY']
    if 'DEEPSEEK_API_KEY' in st.secrets:
        os.environ['DEEPSEEK_API_KEY'] = st.secrets['DEEPSEEK_API_KEY']
    logger.info("API keys è®¾ç½®æˆåŠŸ")
except Exception as e:
    logger.error(f"API å¯†é’¥é…ç½®å¤±è´¥: {str(e)}")
    st.error(f"APIå¯†é’¥é…ç½®å¤±è´¥: {str(e)}")
    st.stop()

# å…¶ä»–å¯¼å…¥
import pandas as pd
from agent_case_match10 import (
    TAG_SYSTEM,
    process_student_case,
    process_student_case2,
    PromptTemplates
)
import json
import io

def convert_to_student_info(row):
    """å°†Excelè¡Œæ•°æ®è½¬æ¢ä¸ºæ ‡å‡†çš„student_infoæ ¼å¼"""
    student_info = {
        "basic_info": {
            "name": str(row['åºå·']),
            "education": {
                "school": row['æ¯•ä¸šé™¢æ ¡'],
                "major_name": row['ä¸“ä¸šåç§°'],
                "major_orientation": row['ä¸“ä¸šæ–¹å‘'],
                "gpa": row['GPAæˆç»©'],
                "language_score": row['è¯­è¨€è€ƒè¯•æˆç»©'],
                "Standardized_exam_scores": row['æ ‡åŒ–è€ƒè¯•æˆç»©'],
                
            }
        },
        "application_intent": {
            "target_countries": [country.strip() for country in row['ç­¾çº¦å›½å®¶'].split(',')],
            "degree_level": row['ç•™å­¦ç±»åˆ«å”¯ä¸€'],
            "target_schools": {
                "has_top_schools": "æ˜¯" if str(row['æ˜¯å¦åŒ…å«åæ ¡']).lower().strip() in [
                    'yes', 'true', 'æ˜¯', '1', 'y', 't', 'true', 'åŒ…å«',
                    'include', 'included', 'éœ€è¦', 'need', 'needed',
                    'è¦', 'å¯¹', 'å¥½', 'ok', 'âˆš', 'âœ“', 'æœ‰'
                ] else "å¦"
            }
        },
        "special_requirements": {
            "special_notes": str(row.get('å¤‡æ³¨ä¿¡æ¯', '')),
        }
    }
    return student_info

def process_excel_custom(df, tag_system, output_tags, progress_bar, status_text, current_prompt):
    """å¤„ç†Excelæ•°æ®å¹¶è¿”å›ç»“æœDataFrame"""
    df['åºå·'] = range(1, len(df) + 1)
    results = []
    
    total_rows = len(df)
    for idx, row in df.iterrows():
        try:
            # æ›´æ–°è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
            current_progress = (idx - df.index[0] + 1) / total_rows  # ä¿®æ­£è¿›åº¦è®¡ç®—
            progress_bar.progress(current_progress)
            status_text.text(f"æ­£åœ¨å¤„ç†ç¬¬ {idx + 1}/{df.index[-1] + 1} æ¡æ•°æ®ï¼š{row['æ¯•ä¸šé™¢æ ¡']} - {row['ä¸“ä¸šåç§°']}")
            
            # è½¬æ¢æ•°æ®æ ¼å¼
            student_info = convert_to_student_info(row)
            print(student_info)
            # å¤„ç†å•ä¸ªå­¦ç”Ÿæ¡ˆä¾‹
            with st.expander(f"ç¬¬ {idx + 1} æ¡ï¼š{row['æ¯•ä¸šé™¢æ ¡']} - {row['ä¸“ä¸šåç§°']}", expanded=False):
                st.write("æ­£åœ¨åˆ†ææ ‡ç­¾...")
                result = process_student_case(student_info, tag_system, current_prompt)
                
                if result["status"] == "success":
                    st.write("âœ… æ ‡ç­¾åŒ¹é…å®Œæˆ")
                    st.write("ğŸ·ï¸ æ ‡ç­¾åŒ¹é…ç»“æœï¼š")
                    tags = result["recommended_tags"]["recommended_tags"]
                    
                    # å±•ç¤ºæ‰€æœ‰æ ‡ç­¾ç±»åˆ«
                    st.write("ğŸŒ å›½å®¶æ ‡ç­¾ï¼š", ", ".join(tags.get("countries", [])))
                    st.write("ğŸ“š ä¸“ä¸šæ ‡ç­¾ï¼š", ", ".join(tags.get("majors", [])))
                    st.write("ğŸ« é™¢æ ¡å±‚æ¬¡ï¼š", ", ".join(tags.get("schoolLevel", [])))
                    st.write("ğŸ¯ ç‰¹æ®Šé¡¹ç›®æ ‡ç­¾ï¼š", ", ".join(tags.get("SpecialProjects", [])))
                    st.write("ğŸ“‹ è¡Œä¸šç»éªŒæ ‡ç­¾ï¼š", ", ".join(tags.get("Industryexperience", [])))
                    st.write("ğŸ“‹ é¡¾é—®èƒŒæ™¯æ ‡ç­¾ï¼š", ", ".join(tags.get("Consultantbackground", [])))
                    st.write("ğŸ“‹ ä¸šåŠ¡æ‰€åœ¨åœ°ï¼š", ", ".join(tags.get("businessLocation", [])))
                    
                    # æ„å»ºç»“æœè¡Œ
                    result_row = {
                        "åºå·": row['åºå·'],
                        "æ¯•ä¸šé™¢æ ¡": row['æ¯•ä¸šé™¢æ ¡'],
                        "ä¸“ä¸šåç§°": row['ä¸“ä¸šåç§°'],
                        "ç­¾çº¦å›½å®¶": row['ç­¾çº¦å›½å®¶'],
                        "åŠç†ç±»å‹": row['åŠç†ç±»å‹']
                    }
                    
                    # æ·»åŠ é€‰ä¸­çš„è¾“å‡ºæ ‡ç­¾
                    if "å›½å®¶æ ‡ç­¾" in output_tags:
                        result_row["å›½å®¶æ ‡ç­¾"] = ", ".join(tags.get("countries", []))
                    if "ä¸“ä¸šæ ‡ç­¾" in output_tags:
                        result_row["ä¸“ä¸šæ ‡ç­¾"] = ", ".join(tags.get("majors", []))
                    if "åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ" in output_tags:
                        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æ‰¾å‡ºæ‰€æœ‰åŒ…å«"åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ"çš„æ ‡ç­¾
                        matching_tags = [tag for tag in tags.get("schoolLevel", []) if "åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ" in tag]
                        result_row["åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ"] = "ã€".join(matching_tags) if matching_tags else ""
                    if "é¡¶çº§åæ ¡æˆåŠŸæ¡ˆä¾‹" in output_tags:
                        matching_tags = [tag for tag in tags.get("schoolLevel", []) if "é¡¶çº§åæ ¡æˆåŠŸæ¡ˆä¾‹" in tag]
                        result_row["é¡¶çº§åæ ¡æˆåŠŸæ¡ˆä¾‹"] = "ã€".join(matching_tags) if matching_tags else ""
                    if "åšå£«æˆåŠŸæ¡ˆä¾‹" in output_tags:
                        matching_tags = [tag for tag in tags.get("SpecialProjects", []) if "åšå£«æˆåŠŸæ¡ˆä¾‹" in tag]
                        result_row["åšå£«æˆåŠŸæ¡ˆä¾‹"] = "ã€".join(matching_tags) if matching_tags else ""
                    if "åšå£«ç”³è¯·ç»éªŒ" in output_tags:
                        matching_tags = [tag for tag in tags.get("SpecialProjects", []) if "åšå£«ç”³è¯·ç»éªŒ" in tag]
                        result_row["åšå£«ç”³è¯·ç»éªŒ"] = "ã€".join(matching_tags) if matching_tags else ""
                    if "ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹" in output_tags:
                        matching_tags = [tag for tag in tags.get("SpecialProjects", []) if "ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹" in tag]
                        result_row["ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹"] = "ã€".join(matching_tags) if matching_tags else ""
                    if "ä½é¾„ç•™å­¦ç”³è¯·ç»éªŒ" in output_tags:
                        matching_tags = [tag for tag in tags.get("SpecialProjects", []) if "ä½é¾„ç•™å­¦ç”³è¯·ç»éªŒ" in tag]
                        result_row["ä½é¾„ç•™å­¦ç”³è¯·ç»éªŒ"] = "ã€".join(matching_tags) if matching_tags else ""
                    if "è¡Œä¸šç»éªŒ" in output_tags:
                        result_row["è¡Œä¸šç»éªŒ"] = "ä¸“å®¶Lv. 6+" if "ä¸“å®¶Lv. 6+" in tags.get("Industryexperience", []) else "èµ„æ·±Lv. 3+" if "èµ„æ·±Lv. 3+" in tags.get("Industryexperience", []) else "ç†Ÿç»ƒLv. 1+"
                    if "æ–‡æ¡ˆèƒŒæ™¯" in output_tags:
                        result_row["æ–‡æ¡ˆèƒŒæ™¯"] = "æµ·å½’" if "æµ·å½’" in tags.get("Consultantbackground", [])  else ""
                    if "ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°" in output_tags:
                        result_row["ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°"] = tags.get("businessLocation", [])
                    if "åšè¿‡è¯¥ç”Ÿæ‰€åœ¨é™¢æ ¡çš„å®¢æˆ·" in output_tags:
                        result_row["åšè¿‡è¯¥ç”Ÿæ‰€åœ¨é™¢æ ¡çš„å®¢æˆ·"] = ""

                else:
                    st.write("âŒ å¤„ç†å¤±è´¥")
                    st.error(result["error_message"])
                    result_row = {
                        "åºå·": row['åºå·'],
                        "æ¯•ä¸šé™¢æ ¡": row['æ¯•ä¸šé™¢æ ¡'],
                        "ä¸“ä¸šåç§°": row['ä¸“ä¸šåç§°'],
                        "ç­¾çº¦å›½å®¶": row['ç­¾çº¦å›½å®¶'],
                        "åŠç†ç±»å‹": row['åŠç†ç±»å‹'],
                        "å¤„ç†çŠ¶æ€": "å¤±è´¥",
                        "é”™è¯¯ä¿¡æ¯": result["error_message"]
                    }
            
            results.append(result_row)
            
        except Exception as e:
            st.error(f"å¤„ç†ç¬¬ {idx + 1} æ¡æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            results.append({
                "åºå·": row.get('åºå·', idx + 1),
                "æ¯•ä¸šé™¢æ ¡": row.get('æ¯•ä¸šé™¢æ ¡', ''),
                "ä¸“ä¸šåç§°": row.get('ä¸“ä¸šåç§°', ''),
                "ç­¾çº¦å›½å®¶": row.get('ç­¾çº¦å›½å®¶', ''),
                "åŠç†ç±»å‹": row.get('åŠç†ç±»å‹', ''),
                "å¤„ç†çŠ¶æ€": "å¤±è´¥",
                "é”™è¯¯ä¿¡æ¯": str(e)
            })
    
    return pd.DataFrame(results)

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        # é¦–å…ˆå°è¯•ä» Streamlit secrets è·å–é…ç½®
        if not st.secrets.get("OPENAI_API_KEY"):
            raise ValueError("æœªåœ¨ Streamlit secrets ä¸­æ‰¾åˆ° OPENAI_API_KEY")
            
        config = {
            "OPENAI_API_KEY": st.secrets["OPENAI_API_KEY"],
            "OPENAI_API_BASE": "https://openrouter.ai/api/v1",
            "OPENAI_MODEL_NAME": "openrouter/google/gemini-2.0-flash-001"
        }
        return config
        
    except Exception as e:
        st.error(f"ä» Streamlit secrets è·å–é…ç½®å¤±è´¥: {str(e)}")
        return None

def initialize_config():
    """åˆå§‹åŒ–é…ç½®"""
    try:
        config = load_config()
        if not config:
            raise ValueError("æ— æ³•åŠ è½½é…ç½®")
            
        
        
        return config
        
    except Exception as e:
        raise Exception(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("è¿›å…¥ä¸»å‡½æ•°")
    
    # åˆå§‹åŒ– session_state å˜é‡
    if 'tagged_data' not in st.session_state:
        st.session_state.tagged_data = None
    if 'merged_df' not in st.session_state:
        st.session_state.merged_df = None
    if 'prompt_templates' not in st.session_state:
        st.session_state.prompt_templates = PromptTemplates()
    
    # åˆå§‹åŒ–æ¨¡å‹é€‰æ‹©çš„session state
    if 'current_model' not in st.session_state:
        st.session_state.current_model = st.secrets['OPENAI_MODEL_NAME']  # é»˜è®¤å€¼
    
    # åœ¨ç³»ç»Ÿé…ç½®éƒ¨åˆ†æ·»åŠ æ¨¡å‹é€‰æ‹©
    st.sidebar.subheader("æ¨¡å‹é…ç½®")
    model_options = [
        "google/gemini-2.0-flash-001",
        "deepseek/deepseek-r1-distill-llama-70b:free",
        "deepseek/deepseek-r1-distill-llama-70b",
        "deepseek/deepseek-r1:free",
        "deepseek/deepseek-r1",
        "anthropic/claude-3.5-haiku",
        "openai/gpt-4o-mini",
        ""
    ]
    
    selected_model = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        options=model_options,
        index=model_options.index(st.session_state.current_model) if st.session_state.current_model in model_options else 0
    )
    
    # æ·»åŠ åº”ç”¨æŒ‰é’®
    if st.sidebar.button("åº”ç”¨æ¨¡å‹è®¾ç½®"):
        st.session_state.current_model = selected_model
        os.environ['OPENAI_MODEL_NAME'] = selected_model
        st.sidebar.success(f"âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹: {selected_model}")
        st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ä»¥åº”ç”¨æ–°è®¾ç½®
    
    # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹
    st.sidebar.info(f"å½“å‰ä½¿ç”¨æ¨¡å‹: {st.session_state.current_model}")
    
    # åˆ›å»ºä¸¤ä¸ªæ ‡ç­¾é¡µ
    system_tab1, system_tab2 = st.tabs(["æ ‡ç­¾åŒ¹é…ç³»ç»Ÿ", "é¡¾é—®åŒ¹é…ç³»ç»Ÿ"])
    
    with system_tab1:
        st.title("ç•™å­¦ç”³è¯·æ ‡ç­¾åŒ¹é…ç³»ç»Ÿ")
        # åˆå§‹åŒ–é…ç½®
        try:
            config = initialize_config()
            if not config:
                st.error("é…ç½®åˆå§‹åŒ–å¤±è´¥ï¼šæ— æ³•è·å–é…ç½®")
                return
            
            if not config.get("OPENAI_API_KEY"):
                st.error("æœªæ‰¾åˆ° OpenAI API å¯†é’¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
                return
            
            # éªŒè¯ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
            if st.secrets.get("OPENAI_API_KEY"):
                logger.info("API é…ç½®éªŒè¯æˆåŠŸ")
                st.success("âœ… APIé…ç½®æˆåŠŸ")
            
            # åˆ›å»ºæç¤ºè¯æ¨¡æ¿å®ä¾‹å¹¶å­˜å‚¨åœ¨session_stateä¸­
            if 'prompt_templates' not in st.session_state:
                logger.info("åˆå§‹åŒ–æç¤ºè¯æ¨¡æ¿")
                st.session_state.prompt_templates = PromptTemplates()
            
            # ä½¿ç”¨session_stateä¸­çš„prompt_templates
            prompt_templates = st.session_state.prompt_templates
            
            # ä¾§è¾¹æ é…ç½®éƒ¨åˆ†
            st.sidebar.header("ç³»ç»Ÿé…ç½®")
            
            # æ ‡ç­¾æå–é…ç½®
            st.sidebar.subheader("æ ‡ç­¾æå–é…ç½®")

            # Agent backstory
            with st.sidebar.expander("æ ‡ç­¾ä¸“å®¶è§’è‰²è®¾å®š", expanded=False):
                tag_backstory = st.text_area(
                    "è§’è‰²è®¾å®š",
                    value=prompt_templates.get_template('tag_specialist'),
                    height=200
                )

            # Task description
            with st.sidebar.expander("æ ‡ç­¾æå–ä»»åŠ¡è¯´æ˜", expanded=False):
                tag_task = st.text_area(
                    "ä»»åŠ¡è¯´æ˜",
                    value=prompt_templates.get_template('tag_task'),
                    height=200
                )

            with st.sidebar.expander("æ ‡ç­¾è¾“å‡ºç»“æ„"):
                tag_recommendation_structure = st.text_area(
                    "æ ‡ç­¾è¾“å‡ºç»“æ„",
                    value=prompt_templates.get_template('tag_recommendation_structure'),
                    height=200
                )

            # æ›´æ–°æŒ‰é’®
            if st.sidebar.button("æ›´æ–°æç¤ºè¯", key="update_prompts"):
                prompt_templates.update_template('tag_specialist', tag_backstory)
                prompt_templates.update_template('tag_task', tag_task)
                prompt_templates.update_template('tag_recommendation_structure', tag_recommendation_structure)
                st.session_state.prompt_templates = prompt_templates
                st.write("æ›´æ–°åçš„æç¤ºè¯ï¼š", st.session_state.prompt_templates.get_template('tag_specialist'))
                st.write("æ›´æ–°åçš„æ ‡ç­¾æå–ä»»åŠ¡è¯´æ˜ï¼š", st.session_state.prompt_templates.get_template('tag_task'))
                st.write("æ›´æ–°åçš„æ ‡ç­¾è¾“å‡ºç»“æ„ï¼š", st.session_state.prompt_templates.get_template('tag_recommendation_structure'))
                st.sidebar.success("âœ… æç¤ºè¯å·²æ›´æ–°ï¼")
            
            # åˆ†æç»“æœç¤ºä¾‹å±•ç¤º
            with st.sidebar.expander("æŸ¥çœ‹åˆ†æç»“æœç¤ºä¾‹"):
                st.markdown("""
                **1. è¾“å…¥æ•°æ®æ ¼å¼ç¤ºä¾‹ï¼š**
                ```json
                student_info = {
                        "basic_info": {
                            "name": str(row['åºå·']),
                            "education": {
                                "school": row['æ¯•ä¸šé™¢æ ¡'],
                                "major_name": row['ä¸“ä¸šåç§°'],
                                "major_orientation": row['ä¸“ä¸šæ–¹å‘'],
                                "gpa": row['GPAæˆç»©'],
                                "language_score": row['è¯­è¨€è€ƒè¯•æˆç»©'],
                                "Standardized_exam_scores": row['æ ‡åŒ–è€ƒè¯•æˆç»©'],
                                
                            }
                        },
                        "application_intent": {
                            "target_countries": [country.strip() for country in row['ç­¾çº¦å›½å®¶'].split(',')],
                            "degree_level": row['ç•™å­¦ç±»åˆ«å”¯ä¸€'],
                            "target_schools": {
                                "has_top_schools": "æ˜¯" if str(row['æ˜¯å¦åŒ…å«åæ ¡']).lower().strip() in [
                                    'yes', 'true', 'æ˜¯', '1', 'y', 't', 'true', 'åŒ…å«',
                                    'include', 'included', 'éœ€è¦', 'need', 'needed',
                                    'è¦', 'å¯¹', 'å¥½', 'ok', 'âˆš', 'âœ“', 'æœ‰'
                                ] else "å¦"
                            }
                        },
                        "special_requirements": {
                            "special_notes": str(row.get('å¤‡æ³¨ä¿¡æ¯', '')),
                        }
                    }
                ```
                **2. æ ‡ç­¾ä½“ç³»ç¤ºä¾‹ï¼š**
                ```json
                TAG_SYSTEM = {
                    "countries": [
                        "ä¸­å›½å¤§é™†", "ä¸­å›½æ¾³é—¨", "ä¸­å›½é¦™æ¸¯", "ä¸¹éº¦", "ä¿„ç½—æ–¯", "åŠ æ‹¿å¤§",
                        "åŒˆç‰™åˆ©", "å¥¥åœ°åˆ©", "å¾·å›½", "æ„å¤§åˆ©", "æŒªå¨", "æ–°åŠ å¡", 
                        "æ–°è¥¿å…°", "æ—¥æœ¬", "æ¯”åˆ©æ—¶", "æ³•å›½", "æ³°å›½", "æ¾³å¤§åˆ©äºš",
                        "çˆ±å°”å…°", "ç‘å…¸", "ç‘å£«", "ç¾å›½", "èŠ¬å…°", "è‹±å›½",
                        "è·å…°", "è¥¿ç­ç‰™", "éŸ©å›½", "é©¬æ¥è¥¿äºš"
                    ],
                    "majors": [
                        "è®¡ç®—æœºä¸ä¿¡æ¯ç³»ç»Ÿ", "åœŸæœ¨ä¸ç¯å¢ƒ", "ç”Ÿç‰©ä¸åŒ»å­¦", "æœºæ¢°ä¸å·¥ç¨‹",
                        "æ•°å­¦ä¸ç»Ÿè®¡", "æ³•å­¦", "å›½é™…å…³ç³»ä¸æ”¿ç­–", "å¿ƒç†å­¦",
                        "å•†ç§‘ç®¡ç†", "é‡‘èä¸ä¼šè®¡", "ç»æµå­¦",
                        "ä¼ åª’ä¸æ–°é—»", "è¯­è¨€ä¸æ–‡å­¦", "äººæ–‡å­¦ç§‘", "æ•™è‚²å­¦", "è‰ºæœ¯å­¦"
                    ],
                    "schoolLevel": [
                        "åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ", "é¡¶çº§åæ ¡æˆåŠŸæ¡ˆä¾‹"
                    ],
                    "SpecialProjects": [
                        "åšå£«ç”³è¯·ç»éªŒ", "åšå£«æˆåŠŸæ¡ˆä¾‹", "ä½é¾„ç•™å­¦ç”³è¯·ç»éªŒ", "ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹"
                    ],
                    "Industryexperience": [
                        "ç†Ÿç»ƒLv. 1+", "èµ„æ·±Lv. 3+", "ä¸“å®¶Lv. 6+"
                    ],
                    "Consultantbackground": [
                        "æµ·å½’"
                    ],
                    "businessLocation": [
                        "ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°"
                    ]
                }
                **3. æ ‡ç­¾æå–ç»“æœç¤ºä¾‹ï¼š**
                ```json
                {
                  "recommended_tags": {
                    "countries": ["string, å›½å®¶æ ‡ç­¾"],
                    "majors": ["string, ä¸“ä¸šæ ‡ç­¾"],
                    "schoolLevel": ["string, é™¢æ ¡å±‚æ¬¡"],
                    "SpecialProjects": ["string, ç‰¹æ®Šé¡¹ç›®æ ‡ç­¾"],
                    "Industryexperience": ["string, è¡Œä¸šç»éªŒæ ‡ç­¾"],
                    "Consultantbackground  ": ["string, é¡¾é—®èƒŒæ™¯æ ‡ç­¾"],
                    "businessLocation": ["string, ä¸šåŠ¡æ‰€åœ¨åœ°"],
                  }
                }
                ```
                """)
            
            # é€‰æ‹©è¾“å‡ºæ ‡ç­¾
            st.sidebar.subheader("è¾“å‡ºæ ‡ç­¾é€‰æ‹©")
            output_tags = st.sidebar.multiselect(
                "é€‰æ‹©éœ€è¦è¾“å‡ºçš„æ ‡ç­¾",
                options=[
                    "å›½å®¶æ ‡ç­¾", "ä¸“ä¸šæ ‡ç­¾", "åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ", "é¡¶çº§åæ ¡æˆåŠŸæ¡ˆä¾‹", "åšå£«æˆåŠŸæ¡ˆä¾‹", "åšå£«ç”³è¯·ç»éªŒ",
                    "ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹", "ä½é¾„ç•™å­¦ç”³è¯·ç»éªŒ", "è¡Œä¸šç»éªŒ","æ–‡æ¡ˆèƒŒæ™¯", "ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°",'åšè¿‡è¯¥ç”Ÿæ‰€åœ¨é™¢æ ¡çš„å®¢æˆ·'
                ],
                default=["å›½å®¶æ ‡ç­¾","ä¸“ä¸šæ ‡ç­¾", "åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ", "é¡¶çº§åæ ¡æˆåŠŸæ¡ˆä¾‹", "åšå£«æˆåŠŸæ¡ˆä¾‹", "åšå£«ç”³è¯·ç»éªŒ",
                    "ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹", "ä½é¾„ç•™å­¦ç”³è¯·ç»éªŒ", "è¡Œä¸šç»éªŒ","æ–‡æ¡ˆèƒŒæ™¯", "ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°","åšè¿‡è¯¥ç”Ÿæ‰€åœ¨é™¢æ ¡çš„å®¢æˆ·"]
            )
            
            # æ·»åŠ é€‰é¡¹å¡æ¥åˆ‡æ¢è¾“å…¥æ–¹å¼
            input_tab1, input_tab2 = st.tabs(["Excelæ–‡ä»¶ä¸Šä¼ ", "æ‰‹åŠ¨è¾“å…¥"])
            
            with input_tab1:
                # æ–‡ä»¶ä¸Šä¼ å’Œå¤„ç†éƒ¨åˆ†
                uploaded_file = st.file_uploader("ä¸Šä¼ Excelæ–‡ä»¶", type=['xlsx', 'xls'])
                
                if uploaded_file is not None:
                    try:
                        logger.info(f"å¼€å§‹å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶: {uploaded_file.name}")
                        # è¯»å–Excelæ–‡ä»¶
                        df = pd.read_excel(uploaded_file)
                        st.write("åŸå§‹æ•°æ®é¢„è§ˆï¼š")
                        st.dataframe(df.head())

                        # æ˜¾ç¤ºæ•°æ®æ€»æ¡æ•°
                        total_rows = len(df)
                        st.info(f"ğŸ“Š æˆåŠŸåŠ è½½æ•°æ®ï¼šå…± {total_rows} æ¡è®°å½•")

                        
                        # é€‰æ‹©æ•°æ®èŒƒå›´
                        start_idx = st.number_input("èµ·å§‹ç´¢å¼•", min_value=1, max_value=len(df), value=1)
                        end_idx = st.number_input("ç»“æŸç´¢å¼•", min_value=start_idx, max_value=len(df), value=min(len(df), start_idx+9))
                        
                        # åˆ›å»ºè¿›åº¦æ¡
                        progress_bar = st.progress(0)
                        
                        # æ·»åŠ åˆ†ææŒ‰é’®
                        analyze_button = st.button("å¼€å§‹åˆ†æ")
                        
                        if analyze_button:
                            # éªŒè¯é€‰æ‹©èŒƒå›´
                            if start_idx > end_idx:
                                st.error("èµ·å§‹ä½ç½®ä¸èƒ½å¤§äºç»“æŸä½ç½®")
                                return
                            
                            # éªŒè¯æç¤ºè¯æ˜¯å¦æ­£ç¡®ä¼ é€’
                            st.write("å½“å‰ä½¿ç”¨çš„æç¤ºè¯ï¼š")
                            st.write("æ ‡ç­¾ä¸“å®¶è§’è‰²è®¾å®šï¼š", st.session_state.prompt_templates.get_template('tag_specialist'))
                            st.write("æ ‡ç­¾æå–ä»»åŠ¡è¯´æ˜ï¼š", st.session_state.prompt_templates.get_template('tag_task'))
                            
                            with st.spinner(f"æ­£åœ¨å¤„ç†ç¬¬ {start_idx} åˆ°ç¬¬ {end_idx} æ¡æ•°æ®..."):
                                # ä½¿ç”¨session_stateä¸­çš„prompt_templates
                                current_prompt = st.session_state.prompt_templates
                                
                                # é€‰æ‹©æŒ‡å®šèŒƒå›´çš„æ•°æ®è¿›è¡Œå¤„ç†
                                selected_df = df.iloc[start_idx-1:end_idx]
                                
                                # å¤„ç†é€‰ä¸­çš„æ•°æ®
                                results_df = process_excel_custom(
                                    selected_df, 
                                    TAG_SYSTEM, 
                                    output_tags, 
                                    progress_bar, 
                                    st.empty(),
                                    current_prompt  # ä¼ é€’å½“å‰çš„prompt_templates
                                )
                                
                                # æ¸…é™¤è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
                                progress_bar.empty()
                                st.empty().empty()
                                
                                # æ˜¾ç¤ºå®Œæˆæ¶ˆæ¯
                                st.success("âœ… åˆ†æå®Œæˆï¼")
                                
                                # æ˜¾ç¤ºç»“æœé¢„è§ˆ
                                st.subheader("åˆ†æç»“æœé¢„è§ˆ")
                                st.dataframe(results_df)
                                
                                # å¤„ç†å®Œæˆåï¼Œä¿å­˜å¸¦æ ‡ç­¾çš„æ•°æ®
                                st.session_state.tagged_data = results_df  # ä¿å­˜å¤„ç†åçš„æ•°æ®
                                
                                # ä¿å­˜Excelæ–‡ä»¶
                                output_filename = f'æ ‡ç­¾åˆ†æç»“æœ_{start_idx}-{end_idx}.xlsx'
                                
                                # ä½¿ç”¨BytesIOé¿å…ä¿å­˜åˆ°ç£ç›˜
                                buffer = io.BytesIO()
                                with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                                    results_df.to_excel(writer, index=False, sheet_name='åˆ†æç»“æœ')
                                    # è·å–workbookå’Œworksheetå¯¹è±¡
                                    workbook = writer.book
                                    worksheet = writer.sheets['åˆ†æç»“æœ']
                                    
                                    # è°ƒæ•´åˆ—å®½
                                    for idx, col in enumerate(results_df.columns):
                                        max_length = max(
                                            results_df[col].astype(str).apply(len).max(),
                                            len(str(col))
                                        )
                                        worksheet.set_column(idx, idx, max_length)
                                
                                # ä¸‹è½½æŒ‰é’®
                                st.download_button(
                                    label="ä¸‹è½½Excelæ ¼å¼ç»“æœ",
                                    data=buffer.getvalue(),
                                    file_name=output_filename,
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                    
                    except Exception as e:
                        logger.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                        st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")

            with input_tab2:
                st.subheader("æ‰‹åŠ¨è¾“å…¥å­¦ç”Ÿæ¡ˆä¾‹")
                
                # æ·»åŠ æ–‡æœ¬è¾“å…¥åŒºåŸŸ
                student_case = st.text_area(
                    "è¯·è¾“å…¥å­¦ç”Ÿæ¡ˆä¾‹ä¿¡æ¯",
                    height=300,
                    placeholder="""è¯·ç”¨è‡ªç„¶è¯­è¨€æè¿°å­¦ç”Ÿçš„åŸºæœ¬æƒ…å†µï¼Œä¾‹å¦‚ï¼š
                        è¿™æ˜¯ä¸€ä½æ¥è‡ªæµ™æ±Ÿå¤§å­¦çš„å­¦ç”Ÿï¼Œè®¡ç®—æœºä¸“ä¸šï¼ŒGPA 3.8/4.0ã€‚æ‰˜ç¦æˆç»©100åˆ†ï¼ŒGRE 320åˆ†ã€‚
                        å¸Œæœ›ç”³è¯·ç¾å›½çš„ç¡•å£«é¡¹ç›®ï¼Œç›®æ ‡é™¢æ ¡åŒ…å«TOP30åæ ¡ã€‚è®¡åˆ’2025å¹´ç§‹å­£å…¥å­¦ã€‚
                        å­¦ç”Ÿæœ‰ç›¸å…³å®ä¹ ç»å†å’Œç ”ç©¶ç»éªŒ..."""
                )
                
                # æ·»åŠ ç¤ºä¾‹æŒ‰é’®
                
                #if st.button("åŠ è½½ç¤ºä¾‹æ¡ˆä¾‹", key="load_example"):
                #    example_case = """è¿™æ˜¯ä¸€ä½æ¥è‡ªæµ™æ±Ÿå¤§å­¦çš„å¤§å››å­¦ç”Ÿï¼Œå°±è¯»äºè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸šï¼Œä¸“ä¸šæ–¹å‘æ˜¯äººå·¥æ™ºèƒ½ã€‚
                #        å­¦æœ¯è¡¨ç°ä¼˜ç§€ï¼ŒGPAè¾¾åˆ°3.8/4.0ï¼Œæ‰˜ç¦æˆç»©100åˆ†ï¼ŒGREæ€»åˆ†320åˆ†ã€‚

                #        ç”³è¯·æ„å‘ï¼š
                #        - ç›®æ ‡å›½å®¶ï¼šç¾å›½
                #        - ç”³è¯·é¡¹ç›®ï¼šè®¡ç®—æœºç§‘å­¦ç¡•å£«
                #        - ç”³è¯·æ•°é‡ï¼šè®¡åˆ’ç”³è¯·12æ‰€å­¦æ ¡
                #        - åŒ…å«åæ ¡ï¼šå¸Œæœ›ç”³è¯·TOP30é™¢æ ¡
                #        - å…¥å­¦æ—¶é—´ï¼š2025å¹´ç§‹å­£å…¥å­¦

                #        ç‰¹æ®Šè¯´æ˜ï¼š
                #        - æœ‰æœºå™¨å­¦ä¹ ç›¸å…³ç ”ç©¶ç»å†
                #        - æ›¾åœ¨å­—èŠ‚è·³åŠ¨å®ä¹ 3ä¸ªæœˆ
                #        - å¸Œæœ›èƒ½ç”³è¯·åˆ°å¥½çš„å­¦æ ¡ï¼Œå¯¹ç»“æœæœ‰è¾ƒé«˜æœŸæœ›
                #        - éœ€è¦è¯¦ç»†çš„ç”³è¯·è§„åˆ’å’ŒæŒ‡å¯¼"""
                    
                #    st.session_state.student_case = example_case
                #    st.rerun()
                
                # æ·»åŠ å¤„ç†æŒ‰é’®
                if st.button("å¼€å§‹åˆ†æ", key="start_analysis") and student_case:
                    with st.spinner("æ­£åœ¨åˆ†æå­¦ç”Ÿæ¡ˆä¾‹..."):
                        try:
                            # åˆ›å»ºä¸€ä¸ªå±•ç¤ºåŒºæ¥æ˜¾ç¤ºå¤„ç†è¿‡ç¨‹
                            thinking_process = st.empty()
                            process_container = st.container()
                            
                            with process_container:
                                st.subheader("ğŸ¤” åˆ†æè¿‡ç¨‹")
                                thinking_area = st.expander("æŸ¥çœ‹è¯¦ç»†åˆ†æè¿‡ç¨‹", expanded=True)
                                
                                with thinking_area:
                                    process_placeholder = st.empty()
                                    messages = []  # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨æ¥å­˜å‚¨æ‰€æœ‰æ¶ˆæ¯
                                    
                                    def update_process(message):
                                        messages.append(message)  # å°†æ–°æ¶ˆæ¯æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                                        # ä½¿ç”¨æ¢è¡Œç¬¦è¿æ¥æ‰€æœ‰æ¶ˆæ¯å¹¶æ˜¾ç¤º
                                        process_placeholder.markdown("\n\n".join(messages))
                                    
                                    # åœ¨å¤„ç†è¿‡ç¨‹ä¸­æ›´æ–°çŠ¶æ€
                                    update_process("ğŸ” å¼€å§‹åˆ†æå­¦ç”Ÿæ¡ˆä¾‹...")
                                    update_process("1ï¸âƒ£ æå–å…³é”®ä¿¡æ¯...")
                                    
                                    # ç›´æ¥å°†æ–‡æœ¬ä¼ ç»™å¤§æ¨¡å‹å¤„ç†ï¼Œå¹¶è·å–å¤„ç†è¿‡ç¨‹
                                    result = process_student_case2(student_case, callback=update_process)
                                    
                                    update_process("âœ… åˆ†æå®Œæˆï¼")

                            if result["status"] == "success":
                                
                                
                                # æ˜¾ç¤ºåŸå§‹è¾“å‡º
                                st.subheader("æ¨¡å‹è¾“å‡ºç»“æœ")
                                st.code(result["raw_output"], language="json")
                                
                                # å¤„ç†æ¨¡å‹è¾“å‡º
                            try:
                                # æ¸…ç†JSONå­—ç¬¦ä¸²
                                json_str = result["raw_output"].replace('```json', '').replace('```', '').strip()
                                # è§£æJSON
                                output_dict = json.loads(json_str)

                                
                                # åˆ›å»ºDataFrame
                                df = pd.DataFrame({
                                    "åºå·": [', '.join(output_dict["recommended_tags"]["index"])],
                                    "å›½å®¶æ ‡ç­¾": [', '.join(output_dict["recommended_tags"]["countries"])],  # ç›´æ¥joinæ•´ä¸ªåˆ—è¡¨
                                    "ä¸“ä¸šæ ‡ç­¾": [', '.join(output_dict["recommended_tags"]["majors"])],
                                    "é™¢æ ¡å±‚æ¬¡": [', '.join(output_dict["recommended_tags"]["schoolLevel"])],
                                    "ç‰¹æ®Šé¡¹ç›®æ ‡ç­¾": [', '.join(output_dict["recommended_tags"]["SpecialProjects"])],
                                    "è¡Œä¸šç»éªŒ": [', '.join(output_dict["recommended_tags"]["Industryexperience"])],
                                    "æ–‡æ¡ˆèƒŒæ™¯": [', '.join(output_dict["recommended_tags"]["Consultantbackground"])],
                                    "ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°": [', '.join(output_dict["recommended_tags"]["businessLocation"])],
                                })
                                
                                # å­˜å…¥session_state
                                st.session_state.tagged_data = df
                                
                                # æ˜¾ç¤ºå¤„ç†åçš„æ•°æ®
                                st.subheader("å¤„ç†åçš„æ ‡ç­¾æ•°æ®")
                                st.dataframe(df)
                                
                                st.success("âœ… æ•°æ®å·²å¤„ç†å¹¶ä¿å­˜åˆ°å†…å­˜ä¸­ï¼Œå¯ç”¨äºåç»­åŒ¹é…")
                                
                            except Exception as e:
                                st.error(f"å¤„ç†æ¨¡å‹è¾“å‡ºæ—¶å‡ºé”™: {str(e)}")
                                st.error("è¯·æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆé¢„æœŸ")
                        
                        except Exception as e:
                            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                    
                elif not student_case and st.button("å¼€å§‹åˆ†æ"):
                    st.warning("è¯·å…ˆè¾“å…¥å­¦ç”Ÿæ¡ˆä¾‹ä¿¡æ¯")
        except Exception as e:
            logger.error(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            st.error(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return

    with system_tab2:
        from match2 import (
            label_merge,
            Consultant_matching
        )
        st.title("é¡¾é—®åŒ¹é…ç³»ç»Ÿ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„æ•°æ®
        if st.session_state.tagged_data is None:
            st.warning("è¯·å…ˆåœ¨æ ‡ç­¾åŒ¹é…ç³»ç»Ÿä¸­å¤„ç†æ•°æ®")
            return
            
        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        with st.container():
            st.subheader("æ•°æ®ä¸Šä¼ ")
            uploaded_consultant_tags = st.file_uploader("è¯·ä¸Šä¼ æ–‡æ¡ˆé¡¾é—®æ ‡ç­¾æ±‡æ€»", type=['xlsx'], key='consultant')
                
            if uploaded_consultant_tags is not None:
                consultant_tags_file = pd.read_excel(uploaded_consultant_tags)
                st.success("é¡¾é—®æ ‡ç­¾æ±‡æ€»ä¸Šä¼ æˆåŠŸ")
            
        # å¤„ç†æŒ‰é’®åŒºåŸŸ
        with st.container():
            st.subheader("æ•°æ®å¤„ç†")
            
            # æ ‡ç­¾è½¬æ¢å¤„ç†æŒ‰é’®
            if st.button("å¼€å§‹æ ‡ç­¾è½¬æ¢å¤„ç†"):
                if st.session_state.tagged_data is not None:  # ä½¿ç”¨sessionä¸­çš„æ ‡ç­¾æ•°æ®
                    try:
                        st.session_state.merged_df = label_merge(st.session_state.tagged_data)
                        st.success("æ ‡ç­¾è½¬æ¢å¤„ç†å®Œæˆï¼")
                        # æ˜¾ç¤ºåˆå¹¶åçš„æ•°æ®é¢„è§ˆ
                        st.write("è½¬æ¢åæ•°æ®é¢„è§ˆï¼š")
                        st.dataframe(st.session_state.merged_df.head())
                            
                        # æ·»åŠ ä¸‹è½½æŒ‰é’®
                        buffer = io.BytesIO()
                        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                            st.session_state.merged_df.to_excel(writer, index=False, sheet_name='æ ‡ç­¾è½¬æ¢ç»“æœ')
                        st.download_button(
                            label="ä¸‹è½½æ ‡ç­¾è½¬æ¢ç»“æœ",
                            data=buffer.getvalue(),
                            file_name="æ ‡ç­¾è½¬æ¢ç»“æœ.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"æ ‡ç­¾è½¬æ¢å¤„ç†å‡ºé”™: {str(e)}")
                else:
                    st.warning("è¯·å…ˆå®Œæˆæ ‡ç­¾å¤„ç†")
            
            st.markdown("---")  # æ·»åŠ åˆ†éš”çº¿
            
            # é¡¾é—®åŒ¹é…æŒ‰é’®
            if st.button("å¼€å§‹é¡¾é—®åŒ¹é…"):
                if uploaded_consultant_tags is not None and st.session_state.merged_df is not None:
                    try:
                        merge_df = st.session_state.merged_df
                        matching_results = Consultant_matching(
                            consultant_tags_file,  # é¡¾é—®æ ‡ç­¾æ•°æ®
                            merge_df  # å·²å¤„ç†çš„æ ‡ç­¾æ•°æ®
                        )
                        st.success("é¡¾é—®åŒ¹é…å®Œæˆï¼")
                        
                        # æ˜¾ç¤ºåŒ¹é…ç»“æœ
                        st.write("åŒ¹é…ç»“æœï¼š")
                        for case, consultants in matching_results.items():
                            st.write(f"\n{case}:")
                            for consultant in consultants:
                                # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                                st.write(f"- {consultant['display']}")
                                # å±•å¼€æ˜¾ç¤ºæ ‡ç­¾åŒ¹é…è¯¦æƒ…
                                with st.expander(f"æŸ¥çœ‹ {consultant['name']} çš„è¯¦ç»†åŒ¹é…ä¿¡æ¯"):
                                    # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
                                    col1, col2 = st.columns(2)
                                    
                                    # ç¬¬ä¸€åˆ—ï¼šé¡¾é—®åŸå§‹æ ‡ç­¾
                                    with col1:
                                        st.subheader("é¡¾é—®åŸå§‹æ ‡ç­¾")
                                        st.write(f"**é¡¾é—®ä¸šåŠ¡å•ä½:** {consultant['businessunits']}")
                                        st.write("**å›½å®¶æ ‡ç­¾:**")
                                        st.write(f"- ç»å¯¹é«˜é¢‘å›½å®¶ï¼š{consultant['ç»å¯¹é«˜é¢‘å›½å®¶']}")
                                        st.write(f"- ç›¸å¯¹é«˜é¢‘å›½å®¶ï¼š{consultant['ç›¸å¯¹é«˜é¢‘å›½å®¶']}")
                                        
                                        st.write("**ä¸“ä¸šæ ‡ç­¾:**")
                                        st.write(f"- ç»å¯¹é«˜é¢‘ä¸“ä¸šï¼š{consultant['ç»å¯¹é«˜é¢‘ä¸“ä¸š']}")
                                        st.write(f"- ç›¸å¯¹é«˜é¢‘ä¸“ä¸šï¼š{consultant['ç›¸å¯¹é«˜é¢‘ä¸“ä¸š']}")
                                        
                                        st.write("**å…¶ä»–æ ‡ç­¾:**")
                                        st.write(f"- è¡Œä¸šç»éªŒï¼š{consultant['è¡Œä¸šç»éªŒ']}")
                                        st.write(f"- ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°ï¼š{consultant['ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°']}")
                                        st.write(f"- å­¦å¹´è´Ÿè·ï¼š{consultant['å­¦å¹´è´Ÿè·']}")
                                        st.write(f"- è¿‘ä¸¤å‘¨è´Ÿè·ï¼š{consultant['è¿‘ä¸¤å‘¨è´Ÿè·']}")
                                        st.write(f"- ä¸ªäººæ„æ„¿ï¼š{consultant['ä¸ªäººæ„æ„¿']}")
                                        
                                        st.write("**ç‰¹æ®Šæ ‡ç­¾:**")
                                        special_tags = [
                                            ('åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ', 'åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ'), 
                                            ('é¡¶çº§åæ ¡æˆåŠŸæ¡ˆä¾‹', 'é¡¶çº§åæ ¡æˆåŠŸæ¡ˆä¾‹'),
                                            ('åšå£«æˆåŠŸæ¡ˆä¾‹', 'åšå£«æˆåŠŸæ¡ˆä¾‹'), 
                                            ('åšå£«ç”³è¯·ç»éªŒ', 'åšå£«ç”³è¯·ç»éªŒ'),
                                            ('ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹', 'ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹'), 
                                            ('ä½é¾„ç•™å­¦ç”³è¯·ç»éªŒ', 'ä½é¾„ç•™å­¦ç”³è¯·ç»éªŒ')
                                        ]
                                        
                                        for tag_name, tag_key in special_tags:
                                            if tag_key in consultant and consultant[tag_key]:
                                                st.write(f"- {tag_name}ï¼š{consultant[tag_key]}")
                                    
                                    # ç¬¬äºŒåˆ—ï¼šåŒ¹é…è¯¦æƒ…ä¸è®¡ç®—è¿‡ç¨‹
                                    with col2:
                                        st.subheader("åŒ¹é…å¾—åˆ†è¯¦æƒ…")
                                        # æ˜¾ç¤ºæ¡ˆä¾‹è¦æ±‚
                                        st.write("**æ¡ˆä¾‹éœ€æ±‚:**")
                                        # è·å–å½“å‰æ¡ˆä¾‹çš„æ ‡ç­¾æ•°æ®
                                        case_id = list(matching_results.keys()).index(case) if case in matching_results else 0
                                        
                                        # å®‰å…¨åœ°å°è¯•è·å–å¯¹åº”è¡Œçš„æ•°æ®
                                        if 'merged_df' in st.session_state and not st.session_state.merged_df.empty:
                                            try:
                                                case_data = st.session_state.merged_df.iloc[case_id]
                                                
                                                # æ˜¾ç¤ºæŒ‡å®šåˆ—çš„æ•°æ®
                                                target_columns = ['å›½å®¶æ ‡ç­¾', 'ä¸“ä¸šæ ‡ç­¾', 'åæ ¡ç”³è¯·ç»éªŒä¸°å¯Œ', 
                                                                'é¡¶çº§åæ ¡æˆåŠŸæ¡ˆä¾‹', 'åšå£«æˆåŠŸæ¡ˆä¾‹', 'åšå£«ç”³è¯·ç»éªŒ',
                                                                'ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹', 'ä½é¾„ç•™å­¦ç”³è¯·ç»éªŒ', 'è¡Œä¸šç»éªŒ']
                                                
                                                for col in target_columns:
                                                    if col in case_data.index and pd.notna(case_data[col]) and case_data[col]:
                                                        st.write(f"- {col}: {case_data[col]}")
                                            except Exception as e:
                                                st.error(f"è·å–æ¡ˆä¾‹æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                                        else:
                                            st.warning("æ²¡æœ‰å¯ç”¨çš„æ¡ˆä¾‹æ ‡ç­¾æ•°æ®")
                                        
                                        # æ˜¾ç¤ºåŒ¹é…è¯¦æƒ…
                                        st.write("**æ ‡ç­¾åŒ¹é…å¾—åˆ†:**")
                                        total_score = 0
                                        
                                        # æ£€æŸ¥æ˜¯å¦æœ‰tag_score_dict
                                        if 'tag_score_dict' in consultant:
                                            tag_details = consultant['tag_score_dict']
                                            
                                            # è·å–å·²è®¡ç®—å¥½çš„åŒ¹é…æ ‡ç­¾æ¯”ä¾‹æ•°æ®
                                            country_count_need = consultant.get('country_count_need', 0)
                                            special_count_need = consultant.get('special_count_need', 0)
                                            other_count_need = consultant.get('other_count_need', 0)
                                            country_count_total = consultant.get('country_count_total', 1)  # é¿å…é™¤é›¶é”™è¯¯
                                            special_count_total = consultant.get('special_count_total', 1)
                                            other_count_total = consultant.get('other_count_total', 1)
                                            country_match_ratio = consultant.get('country_match_ratio', 0)
                                            special_match_ratio = consultant.get('special_match_ratio', 0)
                                            adjusted_country_score = consultant.get('adjusted_country_score', 0)
                                            adjusted_special_score = consultant.get('adjusted_special_score', 0)
                                            other_tags_score = consultant.get('other_tags_score', 0)
                                            country_coverage_ratio = consultant.get('country_coverage_ratio', 0)
                                            special_coverage_ratio = consultant.get('special_coverage_ratio', 0)
                                            # æ˜¾ç¤ºæ ‡ç­¾åŒ¹é…è¯¦æƒ…
                                            for tag, score in tag_details.items():
                                                tag_status = "âœ… åŒ¹é…" if score > 0 else "âŒ æœªåŒ¹é…"
                                                tag_color = "green" if score > 0 else "red"
                                                st.markdown(f"- {tag}: <span style='color:{tag_color}'>{tag_status}</span> ({score}åˆ†)", unsafe_allow_html=True)
                                                total_score += score
                                            
                                            # æ ‡ç­¾å¾—åˆ†å°è®¡
                                            st.markdown(f"æ ‡ç­¾åŒ¹é…å°è®¡: {total_score}åˆ†")
                                            st.markdown(f"**åŒ¹é…ç‡ä¸è¦†ç›–ç‡:**")
                                            st.markdown(f"- å›½å®¶æ ‡ç­¾: åŒ¹é…ç‡ {country_match_ratio:.2f} (åŒ¹é…/æ€»é‡: {country_count_need}/{country_count_total}), è¦†ç›–ç‡ {consultant['country_coverage_ratio']:.2f}")
                                            st.markdown(f"- ç‰¹æ®Šæ ‡ç­¾: åŒ¹é…ç‡ {special_match_ratio:.2f} (åŒ¹é…/æ€»é‡: {special_count_need}/{special_count_total}), è¦†ç›–ç‡ {consultant['special_coverage_ratio']:.2f}")
                                            
                                            # è®¡ç®—æœ€ç»ˆå¾—åˆ†å¹¶æ˜¾ç¤ºè®¡ç®—å…¬å¼
                                            tag_weighted = adjusted_country_score * country_match_ratio * country_coverage_ratio * 0.5 + adjusted_special_score * special_match_ratio * special_coverage_ratio * 0.5 + other_tags_score
                                            workload_score = consultant.get('workload_score', 0)
                                            personal_score = consultant.get('personal_score', 0)
                                            
                                            # æ˜¾ç¤ºå·¥ä½œé‡å’Œä¸ªäººæ„æ„¿è¯„åˆ†
                                            st.write(f"**å·¥ä½œé‡è¯„åˆ†:** {workload_score}åˆ†")
                                            st.write(f"**ä¸ªäººæ„æ„¿è¯„åˆ†:** {personal_score}åˆ†")
                                            
                                            # è®¡ç®—æœ€ç»ˆå¾—åˆ†å¹¶æ˜¾ç¤ºè®¡ç®—å…¬å¼
                                            final_score = tag_weighted + workload_score * 0.3 + personal_score * 0.2
                                            st.write(f"""({adjusted_country_score}) Ã— ({country_match_ratio}) Ã— ({country_coverage_ratio}) Ã— 0.5 + 
                                                      ({adjusted_special_score}) Ã— ({special_match_ratio}) Ã— ({special_coverage_ratio}) Ã— 0.5 + 
                                                      ({other_tags_score}) + ({workload_score}) Ã— 0.3 + ({personal_score}) Ã— 0.2 = {final_score:.1f}åˆ†""")
                                            
                                            # æ˜¾ç¤ºæ€»åˆ†ï¼ˆç¡®ä¿ä¸consultant['score']ä¸€è‡´ï¼‰
                                            st.markdown(f"**æœ€ç»ˆå¾—åˆ†: {consultant['score']:.1f}åˆ†**")
                        
                        # ä¿å­˜åŒ¹é…ç»“æœåˆ° session_state
                        st.session_state.matching_results = matching_results
                        
                    except Exception as e:
                        st.error(f"é¡¾é—®åŒ¹é…å‡ºé”™: {str(e)}")
                else:
                    st.warning("è¯·å…ˆä¸Šä¼ é¡¾é—®æ ‡ç­¾æ±‡æ€»å¹¶å®Œæˆæ ‡ç­¾å¤„ç†")

            # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
            st.markdown("---")  # æ·»åŠ åˆ†éš”çº¿
            st.subheader("å¤„ç†çŠ¶æ€")
            st.write("æ ‡ç­¾å¤„ç†çŠ¶æ€:", "âœ… å®Œæˆ" if st.session_state.merged_df is not None else "â³ å¾…å¤„ç†")
            st.write("é¡¾é—®åŒ¹é…çŠ¶æ€:", "âœ… å®Œæˆ" if 'matching_results' in st.session_state else "â³ å¾…å¤„ç†")

            

if __name__ == "__main__":
    logger.info("å¼€å§‹è¿è¡Œåº”ç”¨")
    main()
    logger.info("åº”ç”¨è¿è¡Œç»“æŸ")

#streamlit run agent/streamlit_app.py