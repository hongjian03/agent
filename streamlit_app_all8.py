import sys
import streamlit as st
import os
import logging
import re

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

# è®°å½•ç¨‹åºå¯åŠ¨
logger.info("ç¨‹åºå¼€å§‹è¿è¡Œ")

# åªåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶æ›¿æ¢ sqlite3
if 'sqlite_setup_done' not in st.session_state:
    try:
        logger.info("å°è¯•è®¾ç½® SQLite")
        __import__('pysqlite3')
        sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
        st.session_state.sqlite_setup_done = True
        logger.info("SQLite è®¾ç½®æˆåŠŸ")
    except Exception as e:
        logger.error(f"SQLite è®¾ç½®é”™è¯¯: {str(e)}")
        st.session_state.sqlite_setup_done = True

# åœ¨æ‰€æœ‰å…¶ä»–å¯¼å…¥ä¹‹å‰ï¼Œå…ˆåˆå§‹åŒ–ç¯å¢ƒå˜é‡

# ç«‹å³è®¾ç½®æ‰€æœ‰éœ€è¦çš„API keys
try:
    logger.info("å¼€å§‹è®¾ç½® API keys")
    os.environ['OPENAI_API_KEY'] = st.secrets['OPENAI_API_KEY']
    os.environ['OPENAI_API_BASE'] = "https://openrouter.ai/api/v1"
    os.environ['OPENAI_MODEL_NAME'] = st.secrets['OPENAI_MODEL_NAME']
    
    # å¦‚æœæœ‰å…¶ä»–keyï¼Œä¹Ÿåœ¨è¿™é‡Œè®¾ç½®
    if 'GROQ_API_KEY' in st.secrets:
        os.environ['GROQ_API_KEY'] = st.secrets['GROQ_API_KEY']
    if 'DEEPSEEK_API_KEY' in st.secrets:
        os.environ['DEEPSEEK_API_KEY'] = st.secrets['DEEPSEEK_API_KEY']
    logger.info("API keys è®¾ç½®æˆåŠŸ")
except Exception as e:
    logger.error(f"API å¯†é’¥é…ç½®å¤±è´¥: {str(e)}")
    st.error(f"APIå¯†é’¥é…ç½®å¤±è´¥: {str(e)}")
    st.stop()

# å…¶ä»–å¯¼å…¥
import pandas as pd
from agent_case_match13 import (
    TAG_SYSTEM,
    process_student_case,
    process_student_case2,
    PromptTemplates
)
import json
import io





def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        # é¦–å…ˆå°è¯•ä» Streamlit secrets è·å–é…ç½®
        if not st.secrets.get("OPENAI_API_KEY"):
            raise ValueError("æœªåœ¨ Streamlit secrets ä¸­æ‰¾åˆ° OPENAI_API_KEY")
            
        config = {
            "OPENAI_API_KEY": st.secrets["OPENAI_API_KEY"],
            "OPENAI_API_BASE": "https://openrouter.ai/api/v1",
            "OPENAI_MODEL_NAME": "openrouter/google/gemini-2.0-flash-001"
        }
        return config
        
    except Exception as e:
        st.error(f"ä» Streamlit secrets è·å–é…ç½®å¤±è´¥: {str(e)}")
        return None

def initialize_config():
    """åˆå§‹åŒ–é…ç½®"""
    try:
        config = load_config()
        if not config:
            raise ValueError("æ— æ³•åŠ è½½é…ç½®")
            
        
        
        return config
        
    except Exception as e:
        raise Exception(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("è¿›å…¥ä¸»å‡½æ•°")
    
    # åˆå§‹åŒ– session_state å˜é‡
    if 'tagged_data' not in st.session_state:
        st.session_state.tagged_data = None
    if 'merged_df' not in st.session_state:
        st.session_state.merged_df = None
    if 'prompt_templates' not in st.session_state:
        st.session_state.prompt_templates = PromptTemplates()
    
    # åˆå§‹åŒ–æ¨¡å‹é€‰æ‹©çš„session state
    if 'current_model' not in st.session_state:
        st.session_state.current_model = st.secrets['OPENAI_MODEL_NAME']  # é»˜è®¤å€¼
    

    # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹
    st.sidebar.info(f"å½“å‰ä½¿ç”¨æ¨¡å‹: {st.session_state.current_model}")
    
    # åˆ›å»ºä¸‰ä¸ªæ ‡ç­¾é¡µ
    system_tab1, system_tab2, system_tab3 = st.tabs(["æ ‡ç­¾åŒ¹é…ç³»ç»Ÿ", "æ ‡ç­¾åŒ¹é…AIæç¤ºè¯è®¾ç½®", "é¡¾é—®åŒ¹é…ç³»ç»Ÿ"])
    
    with system_tab1:
        st.title("ç•™å­¦ç”³è¯·æ ‡ç­¾åŒ¹é…ç³»ç»Ÿ")
        # åˆå§‹åŒ–é…ç½®
        try:
            config = initialize_config()
            if not config:
                st.error("é…ç½®åˆå§‹åŒ–å¤±è´¥ï¼šæ— æ³•è·å–é…ç½®")
                return
            
            if not config.get("OPENAI_API_KEY"):
                st.error("æœªæ‰¾åˆ° OpenAI API å¯†é’¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
                return
            
            # éªŒè¯ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
            if st.secrets.get("OPENAI_API_KEY"):
                logger.info("API é…ç½®éªŒè¯æˆåŠŸ")
                st.success("âœ… APIé…ç½®æˆåŠŸ")
            
            # åˆ›å»ºæç¤ºè¯æ¨¡æ¿å®ä¾‹å¹¶å­˜å‚¨åœ¨session_stateä¸­
            if 'prompt_templates' not in st.session_state:
                logger.info("åˆå§‹åŒ–æç¤ºè¯æ¨¡æ¿")
                st.session_state.prompt_templates = PromptTemplates()
            
            # ä½¿ç”¨session_stateä¸­çš„prompt_templates
            prompt_templates = st.session_state.prompt_templates
            
            # é€‰æ‹©è¾“å‡ºæ ‡ç­¾
            st.sidebar.subheader("è¾“å‡ºæ ‡ç­¾é€‰æ‹©")
            output_tags = st.sidebar.multiselect(
                "é€‰æ‹©éœ€è¦è¾“å‡ºçš„æ ‡ç­¾",
                options=[
                    "å›½å®¶æ ‡ç­¾", "ä¸“ä¸šæ ‡ç­¾", "åæ ¡ä¸“å®¶", "åšå£«æˆåŠŸæ¡ˆä¾‹", "ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹", "è¡Œä¸šç»éªŒ","æ–‡æ¡ˆèƒŒæ™¯", "ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°","æ–‡æ¡ˆé¡¾é—®ä¸šåŠ¡å•ä½",'åšè¿‡è¯¥ç”Ÿæ‰€åœ¨é™¢æ ¡çš„å®¢æˆ·'
                ],
                default=["å›½å®¶æ ‡ç­¾","ä¸“ä¸šæ ‡ç­¾", "åæ ¡ä¸“å®¶", "åšå£«æˆåŠŸæ¡ˆä¾‹", "ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹", "è¡Œä¸šç»éªŒ","æ–‡æ¡ˆèƒŒæ™¯", "ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°","æ–‡æ¡ˆé¡¾é—®ä¸šåŠ¡å•ä½","åšè¿‡è¯¥ç”Ÿæ‰€åœ¨é™¢æ ¡çš„å®¢æˆ·"]
            )
            
            # æ·»åŠ é€‰é¡¹å¡æ¥åˆ‡æ¢è¾“å…¥æ–¹å¼
            input_tab1, = st.tabs(["æ‰‹åŠ¨è¾“å…¥"])
            

            with input_tab1:
                st.subheader("æ‰‹åŠ¨è¾“å…¥å­¦ç”Ÿæ¡ˆä¾‹")
                
                # æ·»åŠ æ–‡æœ¬è¾“å…¥åŒºåŸŸ
                student_case = st.text_area(
                    "è¯·è¾“å…¥å­¦ç”Ÿæ¡ˆä¾‹ä¿¡æ¯",
                    height=300,
                    placeholder="""è¯·ç”¨è‡ªç„¶è¯­è¨€æè¿°å­¦ç”Ÿçš„åŸºæœ¬æƒ…å†µï¼Œä¾‹å¦‚ï¼š
                        è¿™æ˜¯ä¸€ä½æ¥è‡ªæµ™æ±Ÿå¤§å­¦çš„å­¦ç”Ÿï¼Œè®¡ç®—æœºä¸“ä¸šï¼ŒGPA 3.8/4.0ã€‚æ‰˜ç¦æˆç»©100åˆ†ï¼ŒGRE 320åˆ†ã€‚
                        å¸Œæœ›ç”³è¯·ç¾å›½çš„ç¡•å£«é¡¹ç›®ï¼Œç›®æ ‡é™¢æ ¡åŒ…å«TOP30åæ ¡ã€‚è®¡åˆ’2025å¹´ç§‹å­£å…¥å­¦ã€‚
                        å­¦ç”Ÿæœ‰ç›¸å…³å®ä¹ ç»å†å’Œç ”ç©¶ç»éªŒ..."""
                )
                
                
                
                # æ·»åŠ å¤„ç†æŒ‰é’®
                if st.button("å¼€å§‹åˆ†æ", key="start_analysis") :
                    if student_case:
                        with st.spinner("æ­£åœ¨åˆ†æå­¦ç”Ÿæ¡ˆä¾‹..."):
                            try:
                                # åˆ›å»ºä¸€ä¸ªå±•ç¤ºåŒºæ¥æ˜¾ç¤ºå¤„ç†è¿‡ç¨‹
                                thinking_process = st.empty()
                                process_container = st.container()
                                
                                with process_container:
                                    st.subheader("ğŸ¤” åˆ†æè¿‡ç¨‹")
                                    thinking_area = st.expander("æŸ¥çœ‹è¯¦ç»†åˆ†æè¿‡ç¨‹", expanded=True)
                                    
                                    with thinking_area:
                                        process_placeholder = st.empty()
                                        messages = []  # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨æ¥å­˜å‚¨æ‰€æœ‰æ¶ˆæ¯
                                        
                                        def update_process(message):
                                            messages.append(message)  # å°†æ–°æ¶ˆæ¯æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                                            # ä½¿ç”¨æ¢è¡Œç¬¦è¿æ¥æ‰€æœ‰æ¶ˆæ¯å¹¶æ˜¾ç¤º
                                            process_placeholder.markdown("\n\n".join(messages))
                                        
                                        # åœ¨å¤„ç†è¿‡ç¨‹ä¸­æ›´æ–°çŠ¶æ€
                                        update_process("ğŸ” å¼€å§‹åˆ†æå­¦ç”Ÿæ¡ˆä¾‹...")
                                        update_process("1ï¸âƒ£ æå–å…³é”®ä¿¡æ¯...")
                                        
                                        # ç›´æ¥å°†æ–‡æœ¬ä¼ ç»™å¤§æ¨¡å‹å¤„ç†ï¼Œå¹¶è·å–å¤„ç†è¿‡ç¨‹
                                        result = process_student_case2(student_case, callback=update_process)
                                        
                                        update_process("âœ… åˆ†æå®Œæˆï¼")

                                if result["status"] == "success":
                                    
                                    
                                    # æ˜¾ç¤ºåŸå§‹è¾“å‡ºï¼ˆæ”¾åœ¨å¯å±•å¼€çš„éƒ¨åˆ†ä¸­ï¼‰
                                    with st.expander("æŸ¥çœ‹åŸå§‹è¾“å‡ºï¼ˆè°ƒè¯•ç”¨ï¼‰", expanded=False):
                                        st.subheader("æ¨¡å‹è¾“å‡ºç»“æœ")
                                        st.code(result["raw_output"], language="json")
                                    
                                    # å¤„ç†æ¨¡å‹è¾“å‡º
                                    try:
                                        # æ¸…ç†JSONå­—ç¬¦ä¸²
                                        json_str = result["raw_output"]
                                        
                                        # 1. ç§»é™¤æ‰€æœ‰ä»£ç å—æ ‡è®°
                                        json_str = json_str.replace('```json', '').replace('```', '').strip()
                                        
                                        # 2. æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª } ä¹‹é—´çš„å†…å®¹
                                        start_idx = json_str.find('{')
                                        end_idx = json_str.rfind('}')
                                        if start_idx != -1 and end_idx != -1:
                                            json_str = json_str[start_idx:end_idx + 1]
                                        
                                        # 3. ç§»é™¤å¯èƒ½çš„å‰å¯¼å’Œå°¾éšæ–‡æœ¬è¯´æ˜
                                        json_str = re.sub(r'^[^{]*', '', json_str)  # ç§»é™¤ç¬¬ä¸€ä¸ª { ä¹‹å‰çš„æ‰€æœ‰å†…å®¹
                                        json_str = re.sub(r'[^}]*$', '', json_str)  # ç§»é™¤æœ€åä¸€ä¸ª } ä¹‹åçš„æ‰€æœ‰å†…å®¹
                                        
                                        # 4. å°è¯•è§£æJSON
                                        try:
                                            output_dict = json.loads(json_str)
                                        except json.JSONDecodeError as e:
                                            st.error(f"JSONè§£æå¤±è´¥: {str(e)}")
                                            st.write("åŸå§‹è¾“å‡º:", result["raw_output"])
                                            st.write("æ¸…ç†åçš„JSONå­—ç¬¦ä¸²:", json_str)
                                            raise Exception("JSONè§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å‡ºæ ¼å¼")

                                        
                                        # æ˜¾ç¤ºå¤„ç†åçš„æ•°æ®
                                        st.subheader("ğŸ“Š åˆ†æç»“æœ")
                                        
                                        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
                                        col1, col2 = st.columns(2)
                                        
                                        with col1:
                                            st.write("ğŸ¯ **åŒ¹é…æ ‡ç­¾**")
                                            if "recommended_tags" in output_dict:
                                                tags = output_dict["recommended_tags"]
                                                
                                                # æ˜¾ç¤ºå›½å®¶æ ‡ç­¾
                                                if tags.get("countries"):
                                                    st.write("**å›½å®¶æ ‡ç­¾ï¼š**", ", ".join(tags["countries"]))
                                                    
                                                # æ˜¾ç¤ºä¸“ä¸šæ ‡ç­¾
                                                if tags.get("majors"):
                                                    st.write("**ä¸“ä¸šæ ‡ç­¾ï¼š**", ", ".join(tags["majors"]))
                                                    
                                                # æ˜¾ç¤ºå…¶ä»–é‡è¦æ ‡ç­¾
                                                if tags.get("schoolLevel"):
                                                    st.write("**é™¢æ ¡å±‚æ¬¡ï¼š**", ", ".join(tags["schoolLevel"]))
                                                    
                                                if tags.get("SpecialProjects"):
                                                    st.write("**ç‰¹æ®Šé¡¹ç›®ï¼š**", ", ".join(tags["SpecialProjects"]))
                                        
                                        with col2:
                                            # æ˜¾ç¤ºå…¶ä»–æ ‡ç­¾
                                            if "recommended_tags" in output_dict:
                                                tags = output_dict["recommended_tags"]
                                                
                                                if tags.get("Industryexperience"):
                                                    st.write("**è¡Œä¸šç»éªŒï¼š**", ", ".join(tags["Industryexperience"]))
                                                    
                                                if tags.get("Consultantbackground"):
                                                    st.write("**é¡¾é—®èƒŒæ™¯ï¼š**", ", ".join(tags["Consultantbackground"]))
                                                    
                                                if tags.get("businessLocation"):
                                                    st.write("**ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°ï¼š**", ", ".join(tags["businessLocation"]))
                                                    
                                                if tags.get("consultant_unit"):
                                                    st.write("**ä¸šåŠ¡å•ä½ï¼š**", ", ".join(tags["consultant_unit"]))

                                        # å¦‚æœæœ‰æœåŠ¡æŒ‡å—ï¼Œæ˜¾ç¤ºåœ¨æ ‡ç­¾ä¸‹æ–¹
                                        if "service_guide" in output_dict:
                                            st.markdown("---")
                                            st.subheader("ğŸ“ ç”³è¯·æœåŠ¡æŒ‡å—")
                                            
                                            with st.expander("ğŸ“Š ç”³è¯·è€…æ·±åº¦åˆ†æ", expanded=True):
                                                st.write(output_dict["service_guide"]["applicant_analysis"])
                                                
                                            with st.expander("ğŸ“ æ–‡ä¹¦ç­–ç•¥é‡ç‚¹", expanded=True):
                                                st.write(output_dict["service_guide"]["writing_strategy"])
                                            
                                            with st.expander("ğŸ¤ æ²Ÿé€šè¦ç‚¹æŒ‡å—", expanded=True):
                                                st.write(output_dict["service_guide"]["communication_guide"])

                                        # åˆ›å»ºDataFrameæ˜¾ç¤ºï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
                                        df = pd.DataFrame({
                                            "æ–‡æ¡ˆé¡¾é—®ä¸šåŠ¡å•ä½": [', '.join(output_dict["recommended_tags"]["consultant_unit"])],
                                            "å›½å®¶æ ‡ç­¾": [', '.join(output_dict["recommended_tags"]["countries"])],
                                            "ä¸“ä¸šæ ‡ç­¾": [', '.join(output_dict["recommended_tags"]["majors"])],
                                            "åæ ¡ä¸“å®¶": [', '.join(output_dict["recommended_tags"]["schoolLevel"])],
                                            "ç‰¹æ®Šé¡¹ç›®æ ‡ç­¾": [', '.join(output_dict["recommended_tags"]["SpecialProjects"])],
                                            "è¡Œä¸šç»éªŒ": [', '.join(output_dict["recommended_tags"]["Industryexperience"])],
                                            "æ–‡æ¡ˆèƒŒæ™¯": [', '.join(output_dict["recommended_tags"]["Consultantbackground"])],
                                            "ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°": [', '.join(output_dict["recommended_tags"]["businessLocation"])],
                                        })
                                        
                                        # å­˜å…¥session_state
                                        st.session_state.tagged_data = df
                                        
                                        # å°†DataFrameæ˜¾ç¤ºæ”¾åœ¨å¯å±•å¼€çš„éƒ¨åˆ†ä¸­
                                        with st.expander("æŸ¥çœ‹æ ‡ç­¾æ•°æ®è¡¨æ ¼", expanded=False):
                                            st.dataframe(df)
                                        
                                        st.success("âœ… æ•°æ®å·²å¤„ç†å¹¶ä¿å­˜åˆ°å†…å­˜ä¸­ï¼Œå¯ç”¨äºåç»­åŒ¹é…")

                                    except Exception as e:
                                        st.error(f"å¤„ç†æ¨¡å‹è¾“å‡ºæ—¶å‡ºé”™: {str(e)}")
                                        st.error("è¯·æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆé¢„æœŸ")
                            
                            except Exception as e:
                                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                        
                    elif not student_case :
                        st.warning("è¯·å…ˆè¾“å…¥å­¦ç”Ÿæ¡ˆä¾‹ä¿¡æ¯")
        except Exception as e:
            logger.error(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            st.error(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return

    with system_tab2:
        st.title("æ ‡ç­¾åŒ¹é…AIæç¤ºè¯è®¾ç½®")
        
        # ä½¿ç”¨session_stateä¸­çš„prompt_templates
        prompt_templates = st.session_state.prompt_templates
        
        # Agent backstory
        st.subheader("æ ‡ç­¾ä¸“å®¶è§’è‰²è®¾å®š")
        tag_backstory = st.text_area(
            "è§’è‰²è®¾å®š",
            value=prompt_templates.get_template('tag_specialist'),
            height=400
        )

        # Task description
        st.subheader("æ ‡ç­¾æå–ä»»åŠ¡è¯´æ˜")
        tag_task = st.text_area(
            "ä»»åŠ¡è¯´æ˜",
            value=prompt_templates.get_template('tag_task'),
            height=400
        )

        st.subheader("æ ‡ç­¾è¾“å‡ºç»“æ„")
        tag_recommendation_structure = st.text_area(
            "æ ‡ç­¾è¾“å‡ºç»“æ„",
            value=prompt_templates.get_template('tag_recommendation_structure'),
            height=400
        )

        # æ›´æ–°æŒ‰é’®
        if st.button("æ›´æ–°æç¤ºè¯", key="update_prompts"):
            prompt_templates.update_template('tag_specialist', tag_backstory)
            prompt_templates.update_template('tag_task', tag_task)
            prompt_templates.update_template('tag_recommendation_structure', tag_recommendation_structure)
            st.session_state.prompt_templates = prompt_templates
            st.success("âœ… æç¤ºè¯å·²æ›´æ–°ï¼")
            
            # æ˜¾ç¤ºæ›´æ–°åçš„æç¤ºè¯
            with st.expander("æŸ¥çœ‹æ›´æ–°åçš„æç¤ºè¯"):
                st.write("æ›´æ–°åçš„è§’è‰²è®¾å®šï¼š", st.session_state.prompt_templates.get_template('tag_specialist'))
                st.write("æ›´æ–°åçš„ä»»åŠ¡è¯´æ˜ï¼š", st.session_state.prompt_templates.get_template('tag_task'))
                st.write("æ›´æ–°åçš„è¾“å‡ºç»“æ„ï¼š", st.session_state.prompt_templates.get_template('tag_recommendation_structure'))

    with system_tab3:
        from match6 import (
            label_merge,
            Consultant_matching
        )
        st.title("é¡¾é—®åŒ¹é…ç³»ç»Ÿ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„æ•°æ®
        if st.session_state.tagged_data is None:
            st.warning("è¯·å…ˆåœ¨æ ‡ç­¾åŒ¹é…ç³»ç»Ÿä¸­å¤„ç†æ•°æ®")
            return
            
        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        with st.container():
            st.subheader("æ•°æ®ä¸Šä¼ ")
            uploaded_consultant_tags = st.file_uploader("è¯·ä¸Šä¼ æ–‡æ¡ˆé¡¾é—®æ ‡ç­¾æ±‡æ€»", type=['xlsx'], key='consultant')
                
            if uploaded_consultant_tags is not None:
                consultant_tags_file = pd.read_excel(uploaded_consultant_tags)
                st.success("é¡¾é—®æ ‡ç­¾æ±‡æ€»ä¸Šä¼ æˆåŠŸ")
            
        # å¤„ç†æŒ‰é’®åŒºåŸŸ
        with st.container():
            st.subheader("æ•°æ®å¤„ç†")
            
            # æ ‡ç­¾è½¬æ¢å¤„ç†æŒ‰é’®
            if st.button("å¼€å§‹æ ‡ç­¾è½¬æ¢å¤„ç†"):
                if st.session_state.tagged_data is not None:  # ä½¿ç”¨sessionä¸­çš„æ ‡ç­¾æ•°æ®
                    try:
                        st.session_state.merged_df = label_merge(st.session_state.tagged_data)
                        st.success("æ ‡ç­¾è½¬æ¢å¤„ç†å®Œæˆï¼")
                        # æ˜¾ç¤ºåˆå¹¶åçš„æ•°æ®é¢„è§ˆ
                        st.write("è½¬æ¢åæ•°æ®é¢„è§ˆï¼š")
                        st.dataframe(st.session_state.merged_df.head())
                            
                        # æ·»åŠ ä¸‹è½½æŒ‰é’®
                        buffer = io.BytesIO()
                        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                            st.session_state.merged_df.to_excel(writer, index=False, sheet_name='æ ‡ç­¾è½¬æ¢ç»“æœ')
                        st.download_button(
                            label="ä¸‹è½½æ ‡ç­¾è½¬æ¢ç»“æœ",
                            data=buffer.getvalue(),
                            file_name="æ ‡ç­¾è½¬æ¢ç»“æœ.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"æ ‡ç­¾è½¬æ¢å¤„ç†å‡ºé”™: {str(e)}")
                else:
                    st.warning("è¯·å…ˆå®Œæˆæ ‡ç­¾å¤„ç†")
            
            st.markdown("---")  # æ·»åŠ åˆ†éš”çº¿
            
            # é¡¾é—®åŒ¹é…æŒ‰é’®
            if st.button("å¼€å§‹é¡¾é—®åŒ¹é…"):
                if uploaded_consultant_tags is not None and st.session_state.merged_df is not None:
                    try:
                        merge_df = st.session_state.merged_df
                        matching_results ,area = Consultant_matching(
                            consultant_tags_file,  # é¡¾é—®æ ‡ç­¾æ•°æ®
                            merge_df  # å·²å¤„ç†çš„æ ‡ç­¾æ•°æ®
                        )
                        st.success("é¡¾é—®åŒ¹é…å®Œæˆï¼")
                        
                        # æ˜¾ç¤ºåŒ¹é…ç»“æœ
                        st.write("åŒ¹é…ç»“æœï¼š")
                        for case, consultants in matching_results.items():
                            st.write(f"\n{case}:")
                            for consultant in consultants:
                                # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                                st.write(f"- {consultant['display']}")
                                # å±•å¼€æ˜¾ç¤ºæ ‡ç­¾åŒ¹é…è¯¦æƒ…
                                with st.expander(f"æŸ¥çœ‹ {consultant['name']} çš„è¯¦ç»†åŒ¹é…ä¿¡æ¯"):
                                    # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
                                    col1, col2 = st.columns(2)
                                    
                                    # ç¬¬ä¸€åˆ—ï¼šé¡¾é—®åŸå§‹æ ‡ç­¾
                                    with col1:
                                        businessunits = consultant.get('businessunits', '')
                                        area = consultant.get('area', '')
                                        area_local = "åœ¨æœ¬åœ°åŒ¹é…" if area else "åœ¨å…¨å›½å¤§æ± é‡ŒåŒ¹é…"
                                        st.subheader("é¡¾é—®åŸå§‹æ ‡ç­¾")
                                        st.write(f"**é¡¾é—®ä¸šåŠ¡å•ä½:** {businessunits}")
                                        st.write(f"**åŒ¹é…èŒƒå›´:** {area_local}")
                                        st.write("**å›½å®¶æ ‡ç­¾:**")
                                        st.write(f"- ç»å¯¹é«˜é¢‘å›½å®¶ï¼š{consultant['ç»å¯¹é«˜é¢‘å›½å®¶']}")
                                        st.write(f"- ç›¸å¯¹é«˜é¢‘å›½å®¶ï¼š{consultant['ç›¸å¯¹é«˜é¢‘å›½å®¶']}")
                                        
                                        st.write("**ä¸“ä¸šæ ‡ç­¾:**")
                                        st.write(f"- ç»å¯¹é«˜é¢‘ä¸“ä¸šï¼š{consultant['ç»å¯¹é«˜é¢‘ä¸“ä¸š']}")
                                        st.write(f"- ç›¸å¯¹é«˜é¢‘ä¸“ä¸šï¼š{consultant['ç›¸å¯¹é«˜é¢‘ä¸“ä¸š']}")
                                        
                                        st.write("**å…¶ä»–æ ‡ç­¾:**")
                                        st.write(f"- è¡Œä¸šç»éªŒï¼š{consultant['è¡Œä¸šç»éªŒ']}")
                                        st.write(f"- ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°ï¼š{consultant['ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°']}")
                                        st.write(f"- å­¦å¹´è´Ÿè·ï¼š{consultant['å­¦å¹´è´Ÿè·']}")
                                        st.write(f"- è¿‘ä¸¤å‘¨è´Ÿè·ï¼š{consultant['è¿‘ä¸¤å‘¨è´Ÿè·']}")
                                        st.write(f"- ä¸ªäººæ„æ„¿ï¼š{consultant['ä¸ªäººæ„æ„¿']}")
                                        
                                        st.write("**ç‰¹æ®Šæ ‡ç­¾:**")
                                        special_tags = [
                                            ('åæ ¡ä¸“å®¶', 'åæ ¡ä¸“å®¶'), 
                                            ('åšå£«æˆåŠŸæ¡ˆä¾‹', 'åšå£«æˆåŠŸæ¡ˆä¾‹'), 
                                            ('ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹', 'ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹')
                                        ]
                                        
                                        for tag_name, tag_key in special_tags:
                                            if tag_key in consultant and consultant[tag_key]:
                                                st.write(f"- {tag_name}ï¼š{consultant[tag_key]}")
                                    
                                    # ç¬¬äºŒåˆ—ï¼šåŒ¹é…è¯¦æƒ…ä¸è®¡ç®—è¿‡ç¨‹
                                    with col2:
                                        st.subheader("åŒ¹é…å¾—åˆ†è¯¦æƒ…")
                                        # æ˜¾ç¤ºæ¡ˆä¾‹è¦æ±‚
                                        st.write("**æ¡ˆä¾‹éœ€æ±‚:**")
                                        # è·å–å½“å‰æ¡ˆä¾‹çš„æ ‡ç­¾æ•°æ®
                                        case_id = list(matching_results.keys()).index(case) if case in matching_results else 0
                                        
                                        # å®‰å…¨åœ°å°è¯•è·å–å¯¹åº”è¡Œçš„æ•°æ®
                                        if 'merged_df' in st.session_state and not st.session_state.merged_df.empty:
                                            try:
                                                case_data = st.session_state.merged_df.iloc[case_id]
                                                
                                                # æ˜¾ç¤ºæŒ‡å®šåˆ—çš„æ•°æ®
                                                target_columns = ['æ–‡æ¡ˆé¡¾é—®ä¸šåŠ¡å•ä½','å›½å®¶æ ‡ç­¾', 'ä¸“ä¸šæ ‡ç­¾', 'åæ ¡ä¸“å®¶', 
                                                                'åšå£«æˆåŠŸæ¡ˆä¾‹', 'ä½é¾„ç•™å­¦æˆåŠŸæ¡ˆä¾‹', 'è¡Œä¸šç»éªŒ','æ–‡æ¡ˆèƒŒæ™¯',
                                                                'ä¸šåŠ¡å•ä½æ‰€åœ¨åœ°']
                                                
                                                for col in target_columns:
                                                    if col in case_data.index and pd.notna(case_data[col]) and case_data[col]:
                                                        st.write(f"- {col}: {case_data[col]}")
                                            except Exception as e:
                                                st.error(f"è·å–æ¡ˆä¾‹æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                                        else:
                                            st.warning("æ²¡æœ‰å¯ç”¨çš„æ¡ˆä¾‹æ ‡ç­¾æ•°æ®")
                                        
                                        # æ˜¾ç¤ºåŒ¹é…è¯¦æƒ…
                                        st.write("**æ ‡ç­¾åŒ¹é…å¾—åˆ†:**")
                                        total_score = 0
                                        
                                        # æ£€æŸ¥æ˜¯å¦æœ‰tag_score_dict
                                        if 'tag_score_dict' in consultant:
                                            tag_details = consultant['tag_score_dict']
                                            
                                            # è·å–å·²è®¡ç®—å¥½çš„åŒ¹é…æ ‡ç­¾æ¯”ä¾‹æ•°æ®
                                            country_count_need = consultant.get('country_count_need', 0)
                                            special_count_need = consultant.get('special_count_need', 0)
                                            other_count_need = consultant.get('other_count_need', 0)
                                            country_count_total = consultant.get('country_count_total', 1)  # é¿å…é™¤é›¶é”™è¯¯
                                            special_count_total = consultant.get('special_count_total', 1)
                                            other_count_total = consultant.get('other_count_total', 1)
                                            country_match_ratio = consultant.get('country_match_ratio', 0)
                                            special_match_ratio = consultant.get('special_match_ratio', 0)
                                            country_tags_score = consultant.get('country_tags_score', 0)
                                            special_tags_score = consultant.get('special_tags_score', 0)
                                            other_tags_score = consultant.get('other_tags_score', 0)
                                            country_coverage_ratio = consultant.get('country_coverage_ratio', 0)
                                            special_coverage_ratio = consultant.get('special_coverage_ratio', 0)
                                            # æ˜¾ç¤ºæ ‡ç­¾åŒ¹é…è¯¦æƒ…
                                            for tag, score in tag_details.items():
                                                tag_status = "âœ… åŒ¹é…" if score > 0 else "âŒ æœªåŒ¹é…"
                                                tag_color = "green" if score > 0 else "red"
                                                st.markdown(f"- {tag}: <span style='color:{tag_color}'>{tag_status}</span> ({score}åˆ†)", unsafe_allow_html=True)
                                                total_score += score
                                            
                                            # æ ‡ç­¾å¾—åˆ†å°è®¡
                                            st.markdown(f"**åŒ¹é…ç‡ä¸è¦†ç›–ç‡:**")
                                            st.markdown(f"- å›½å®¶æ ‡ç­¾: åŒ¹é…ç‡ {country_match_ratio:.2f} (åŒ¹é…/æ€»é‡: {country_count_need}/{country_count_total}), è¦†ç›–ç‡ {consultant['country_coverage_ratio']:.2f}")
                                            st.markdown(f"- ç‰¹æ®Šæ ‡ç­¾: åŒ¹é…ç‡ {special_match_ratio:.2f} (åŒ¹é…/æ€»é‡: {special_count_need}/{special_count_total}), è¦†ç›–ç‡ {consultant['special_coverage_ratio']:.2f}")
                                            
                                            # è®¡ç®—æœ€ç»ˆå¾—åˆ†å¹¶æ˜¾ç¤ºè®¡ç®—å…¬å¼

                                            tag_weighted = country_tags_score * country_match_ratio * country_coverage_ratio * 0.5 + special_tags_score * special_match_ratio * special_coverage_ratio * 0.5 + other_tags_score*0.5
                                            workload_score = consultant.get('workload_score', 0)
                                            personal_score = consultant.get('personal_score', 0)
                                            
                                            # æ˜¾ç¤ºå·¥ä½œé‡å’Œä¸ªäººæ„æ„¿è¯„åˆ†
                                            st.write(f"**å·¥ä½œé‡è¯„åˆ†:** {workload_score}åˆ†")
                                            st.write(f"**ä¸ªäººæ„æ„¿è¯„åˆ†:** {personal_score}åˆ†")
                                            # è®¡ç®—æœ€ç»ˆå¾—åˆ†å¹¶æ˜¾ç¤ºè®¡ç®—å…¬å¼
                                            final_score = tag_weighted + workload_score * 0.3 + personal_score * 0.2
                                            st.write("è®¡ç®—å…¬å¼ï¼šå›½å®¶å¾—åˆ† x å›½å®¶åŒ¹é…ç‡ x å›½å®¶è¦†ç›–ç‡ x 0.5 + ç‰¹æ®Šå¾—åˆ† x ç‰¹æ®ŠåŒ¹é…ç‡ x ç‰¹æ®Šè¦†ç›–ç‡ x 0.5 + å…¶ä»–æ ‡ç­¾å¾—åˆ† x 0.5 + å·¥ä½œé‡å¾—åˆ† x 0.3 + ä¸ªäººæ„æ„¿å¾—åˆ† x 0.2")
                                            st.write(f"""({country_tags_score}) Ã— ({country_match_ratio}) Ã— ({country_coverage_ratio}) Ã— 0.5 + 
                                                      ({special_tags_score}) Ã— ({special_match_ratio}) Ã— ({special_coverage_ratio}) Ã— 0.5 + 
                                                      ({other_tags_score}) Ã— 0.5+ ({workload_score}) Ã— 0.3 + ({personal_score}) Ã— 0.2 = {final_score:.1f}åˆ†""")
                                            
                                            # æ˜¾ç¤ºæ€»åˆ†ï¼ˆç¡®ä¿ä¸consultant['score']ä¸€è‡´ï¼‰
                                            st.markdown(f"**æœ€ç»ˆå¾—åˆ†: {consultant['score']:.1f}åˆ†**")
                        
                        # ä¿å­˜åŒ¹é…ç»“æœåˆ° session_state
                        st.session_state.matching_results = matching_results
                        
                    except Exception as e:
                        st.error(f"é¡¾é—®åŒ¹é…å‡ºé”™: {str(e)}")
                else:
                    st.warning("è¯·å…ˆä¸Šä¼ é¡¾é—®æ ‡ç­¾æ±‡æ€»å¹¶å®Œæˆæ ‡ç­¾å¤„ç†")

            # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
            st.markdown("---")  # æ·»åŠ åˆ†éš”çº¿
            st.subheader("å¤„ç†çŠ¶æ€")
            st.write("æ ‡ç­¾å¤„ç†çŠ¶æ€:", "âœ… å®Œæˆ" if st.session_state.merged_df is not None else "â³ å¾…å¤„ç†")
            st.write("é¡¾é—®åŒ¹é…çŠ¶æ€:", "âœ… å®Œæˆ" if 'matching_results' in st.session_state else "â³ å¾…å¤„ç†")

            

if __name__ == "__main__":
    logger.info("å¼€å§‹è¿è¡Œåº”ç”¨")
    main()
    logger.info("åº”ç”¨è¿è¡Œç»“æŸ")

#streamlit run agent/streamlit_app.py